{"nbformat": 4, "cells": [{"source": "## Overview\n\nThis notebook predicts ratings for new users using the model saved in the previous notebook.", "cell_type": "markdown", "metadata": {}}, {"source": "Manufacture some ratings for a new user.", "cell_type": "markdown", "metadata": {}}, {"source": "from pyspark.mllib.recommendation import Rating\n\nnew_user_ID = 0\n\nnew_user_ratings = [\n     Rating(0,260,9),   # Star Wars (1977)\n     Rating(0,1,8),     # Toy Story (1995)\n     Rating(0,16,7),    # Casino (1995)\n     Rating(0,25,8),    # Leaving Las Vegas (1995)\n     Rating(0,32,9),    # Twelve Monkeys (a.k.a. 12 Monkeys) (1995)\n     Rating(0,335,4),   # Flintstones, The (1994)\n     Rating(0,379,3),   # Timecop (1994)\n     Rating(0,296,7),   # Pulp Fiction (1994)\n     Rating(0,858,10) , # Godfather, The (1972)\n     Rating(0,50,8)     # Usual Suspects, The (1995)\n    ]\n\nnew_user_ratings_RDD = sc.parallelize(new_user_ratings)", "cell_type": "code", "metadata": {"collapsed": false}, "execution_count": 1, "outputs": []}, {"source": "new_user_ratings_RDD.collect()", "cell_type": "code", "metadata": {"collapsed": false}, "execution_count": 2, "outputs": [{"data": {"text/plain": "[Rating(user=0, product=260, rating=9.0),\n Rating(user=0, product=1, rating=8.0),\n Rating(user=0, product=16, rating=7.0),\n Rating(user=0, product=25, rating=8.0),\n Rating(user=0, product=32, rating=9.0),\n Rating(user=0, product=335, rating=4.0),\n Rating(user=0, product=379, rating=3.0),\n Rating(user=0, product=296, rating=7.0),\n Rating(user=0, product=858, rating=10.0),\n Rating(user=0, product=50, rating=8.0)]"}, "execution_count": 2, "metadata": {}, "output_type": "execute_result"}]}, {"source": "Load the original rating dataset", "cell_type": "markdown", "metadata": {}}, {"source": "from pyspark.mllib.recommendation import Rating\n\nratings = sc.textFile('ratings.dat') \\\n               .map(lambda l: l.split(\"::\")) \\\n               .map(lambda p: Rating(\n                                  user = int(p[0]), \n                                  product = int(p[1]),\n                                  rating = float(p[2]), \n                                  ))", "cell_type": "code", "metadata": {"collapsed": false}, "execution_count": 3, "outputs": []}, {"source": "Join the new user ratings with the orginal dataset", "cell_type": "markdown", "metadata": {}}, {"source": "ratings = ratings.union(new_user_ratings_RDD)", "cell_type": "code", "metadata": {"collapsed": true}, "execution_count": 4, "outputs": []}, {"source": "Re-train the model", "cell_type": "markdown", "metadata": {}}, {"source": "from pyspark.mllib.recommendation import ALS\n\nrank = 50\nnumIterations = 20\nlambdaParam = 0.1\nmodel = ALS.train(ratings, rank, numIterations, lambdaParam)", "cell_type": "code", "metadata": {"collapsed": false}, "execution_count": 5, "outputs": []}, {"source": "## Save the model", "cell_type": "markdown", "metadata": {}}, {"source": "In production, training the model will happen in a batch process.", "cell_type": "markdown", "metadata": {}}, {"source": "# if there is an existing model, delete it\n!rm -rf ./recommender_model\n\n# save the model\nmodel.save(sc, './recommender_model')", "cell_type": "code", "metadata": {"collapsed": true}, "execution_count": 6, "outputs": []}, {"source": "## Load the model", "cell_type": "markdown", "metadata": {}}, {"source": "Let's load the model - production code would reload the model every time the model has been updated.<br/>", "cell_type": "markdown", "metadata": {}}, {"source": "from pyspark.mllib.recommendation import MatrixFactorizationModel\n\nmodel = MatrixFactorizationModel.load(sc, './recommender_model')", "cell_type": "code", "metadata": {"collapsed": true}, "execution_count": 7, "outputs": []}, {"source": "## Predict the top 10 movies for the new user\n\nPredict the top 10 movies for the new user based on their other movie ratings", "cell_type": "markdown", "metadata": {}}, {"source": "new_user_rated_movie_ids = map(lambda x: x[1], new_user_ratings)\n\n# new_user_rated_movied_ids = [260, 1, 16, 25, 32, 335, 379, 296, 858, 50]\n\nnew_user_unrated_movies_RDD = ratings.filter(lambda r: r.product not in new_user_rated_movie_ids) \\\n                                     .map(lambda x: (new_user_ID, x[0])) \\\n                                     .distinct()", "cell_type": "code", "metadata": {"collapsed": false}, "execution_count": 8, "outputs": []}, {"source": "Let's take a look at the new_user_unrated_movies_RDD data", "cell_type": "markdown", "metadata": {}}, {"source": "new_user_unrated_movies_RDD.take(5)", "cell_type": "code", "metadata": {"collapsed": false}, "execution_count": 9, "outputs": [{"data": {"text/plain": "[(0, 378), (0, 1934), (0, 3282), (0, 5606), (0, 862)]"}, "execution_count": 9, "metadata": {}, "output_type": "execute_result"}]}, {"source": "new_user_recommendations_RDD = model.predictAll(new_user_unrated_movies_RDD)\n\nprint(new_user_recommendations_RDD.take(10))", "cell_type": "code", "metadata": {"collapsed": false}, "execution_count": 10, "outputs": [{"output_type": "stream", "name": "stdout", "text": "[Rating(user=0, product=1084, rating=7.41803123379617), Rating(user=0, product=3456, rating=7.250149438175512), Rating(user=0, product=3272, rating=5.4176207436700565), Rating(user=0, product=1040, rating=5.485268395607773), Rating(user=0, product=912, rating=8.179587907566159), Rating(user=0, product=140, rating=4.319208170261349), Rating(user=0, product=204, rating=3.435063927802238), Rating(user=0, product=956, rating=6.171745234206328), Rating(user=0, product=3436, rating=3.8179171571136195), Rating(user=0, product=492, rating=6.803288524222469)]\n"}]}, {"source": "You would want to join the above data set to output the movie names and also filter out movies with less than X number of ratings.<br>\nSee https://github.com/jadianes/spark-movie-lens/blob/master/notebooks/building-recommender.ipynb for more info.\n\nNote that some of the ratings are bigger than 5.0.<br>\nFor a possible explation, see http://stackoverflow.com/questions/29051520/apache-spark-als-recommendation", "cell_type": "markdown", "metadata": {}}, {"source": "## Predict how the user would rate a single movie\n\nPredict how the user would rate this new movie", "cell_type": "markdown", "metadata": {}}, {"source": "my_movie = sc.parallelize([(0, 500)]) # Quiz Show (1994)\nindividual_movie_rating_RDD = model.predictAll(my_movie)\nindividual_movie_rating_RDD.collect()", "cell_type": "code", "metadata": {"collapsed": false}, "execution_count": 11, "outputs": [{"data": {"text/plain": "[Rating(user=0, product=500, rating=5.518930176128497)]"}, "execution_count": 11, "metadata": {}, "output_type": "execute_result"}]}, {"source": "", "cell_type": "code", "metadata": {"collapsed": true}, "execution_count": null, "outputs": []}], "metadata": {"language_info": {"file_extension": ".py", "version": "2.7.11", "nbconvert_exporter": "python", "pygments_lexer": "ipython2", "name": "python", "mimetype": "text/x-python", "codemirror_mode": {"version": 2, "name": "ipython"}}, "kernelspec": {"language": "python", "display_name": "Python 2 with Spark 1.6", "name": "python2"}}, "nbformat_minor": 0}