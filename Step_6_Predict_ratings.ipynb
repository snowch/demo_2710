{"cells": [{"cell_type": "markdown", "metadata": {}, "source": "## Overview\n\nThis notebook predicts ratings for new users using the model saved in the previous notebook."}, {"cell_type": "markdown", "metadata": {}, "source": "Manufacture some ratings for a new user."}, {"cell_type": "code", "metadata": {"collapsed": false}, "source": "from pyspark.mllib.recommendation import Rating\n\nnew_user_ID = 0\n\nnew_user_ratings = [\n     Rating(0,260,9),   # Star Wars (1977)\n     Rating(0,1,8),     # Toy Story (1995)\n     Rating(0,16,7),    # Casino (1995)\n     Rating(0,25,8),    # Leaving Las Vegas (1995)\n     Rating(0,32,9),    # Twelve Monkeys (a.k.a. 12 Monkeys) (1995)\n     Rating(0,335,4),   # Flintstones, The (1994)\n     Rating(0,379,3),   # Timecop (1994)\n     Rating(0,296,7),   # Pulp Fiction (1994)\n     Rating(0,858,10) , # Godfather, The (1972)\n     Rating(0,50,8)     # Usual Suspects, The (1995)\n    ]\n\nnew_user_ratings_RDD = sc.parallelize(new_user_ratings)", "outputs": [], "execution_count": 1}, {"cell_type": "markdown", "metadata": {}, "source": "Load the original rating dataset"}, {"cell_type": "code", "metadata": {"collapsed": false}, "source": "from pyspark.mllib.recommendation import Rating\n\nratings = sc.textFile('ratings.dat') \\\n               .map(lambda l: l.split(\"::\")) \\\n               .map(lambda p: Rating(\n                                  user = int(p[0]), \n                                  product = int(p[1]),\n                                  rating = float(p[2]), \n                                  ))", "outputs": [], "execution_count": 2}, {"cell_type": "markdown", "metadata": {}, "source": "Join the new user ratings with the orginal dataset"}, {"cell_type": "code", "metadata": {"collapsed": true}, "source": "ratings = ratings.union(new_user_ratings_RDD)", "outputs": [], "execution_count": 3}, {"cell_type": "markdown", "metadata": {}, "source": "Re-train the model"}, {"cell_type": "code", "metadata": {"collapsed": false}, "source": "from pyspark.mllib.recommendation import ALS\n\nrank = 50\nnumIterations = 20\nlambdaParam = 0.1\nmodel = ALS.train(ratings, rank, numIterations, lambdaParam)", "outputs": [], "execution_count": 4}, {"cell_type": "markdown", "metadata": {}, "source": "## Save the model"}, {"cell_type": "markdown", "metadata": {}, "source": "In production, training the model will happen in a batch process."}, {"cell_type": "code", "metadata": {"collapsed": true}, "source": "# if there is an existing model, delete it\n!rm -rf ./recommender_model\n\n# save the model\nmodel.save(sc, './recommender_model')", "outputs": [], "execution_count": 5}, {"cell_type": "markdown", "metadata": {}, "source": "## Load the model"}, {"cell_type": "markdown", "metadata": {}, "source": "Let's load the model - production code would reload the model every time the model has been updated.<br/>"}, {"cell_type": "code", "metadata": {"collapsed": true}, "source": "from pyspark.mllib.recommendation import MatrixFactorizationModel\n\nmodel = MatrixFactorizationModel.load(sc, './recommender_model')", "outputs": [], "execution_count": 6}, {"cell_type": "markdown", "metadata": {}, "source": "## Predict the top 10 movies for the new user\n\nPredict the top 10 movies for the new user based on their other movie ratings"}, {"cell_type": "code", "metadata": {"collapsed": false}, "source": "new_user_rated_movie_ids = map(lambda x: x[1], new_user_ratings)\n\nnew_user_unrated_movies_RDD = ratings.filter(lambda r: r.product not in new_user_rated_movie_ids) \\\n                                     .map(lambda x: (new_user_ID, x[0])) \\\n                                     .distinct()\n\nnew_user_recommendations_RDD = model.predictAll(new_user_unrated_movies_RDD)\n\nprint(new_user_recommendations_RDD.take(10))", "outputs": [{"output_type": "stream", "name": "stdout", "text": "[Rating(user=0, product=1084, rating=7.398933571067051), Rating(user=0, product=3456, rating=7.3280822530249585), Rating(user=0, product=3272, rating=5.321683191005649), Rating(user=0, product=1040, rating=5.538833525327898), Rating(user=0, product=912, rating=8.16829192168962), Rating(user=0, product=140, rating=4.357318580164231), Rating(user=0, product=204, rating=3.380372500797481), Rating(user=0, product=956, rating=6.259330935443704), Rating(user=0, product=3436, rating=3.9054041519792775), Rating(user=0, product=492, rating=6.792005026587259)]\n"}], "execution_count": 7}, {"cell_type": "markdown", "metadata": {}, "source": "You would want to join the above data set to output the movie names and also filter out movies with less than X number of ratings.<br>\nSee https://github.com/jadianes/spark-movie-lens/blob/master/notebooks/building-recommender.ipynb for more info.\n\nNote that some of the ratings are bigger than 5.0.<br>\nFor a possible explation, see http://stackoverflow.com/questions/29051520/apache-spark-als-recommendation"}, {"cell_type": "markdown", "metadata": {}, "source": "## Predict how the user would rate a single movie\n\nPredict how the user would rate this new movie"}, {"cell_type": "code", "metadata": {"collapsed": false}, "source": "my_movie = sc.parallelize([(0, 500)]) # Quiz Show (1994)\nindividual_movie_rating_RDD = model.predictAll(my_movie)\nindividual_movie_rating_RDD.collect()", "outputs": [{"metadata": {}, "output_type": "execute_result", "data": {"text/plain": "[Rating(user=0, product=500, rating=5.519096770617339)]"}, "execution_count": 8}], "execution_count": 8}, {"cell_type": "code", "metadata": {"collapsed": true}, "source": "", "outputs": [], "execution_count": null}], "metadata": {"kernelspec": {"display_name": "Python 2", "name": "python2", "language": "python"}, "language_info": {"file_extension": ".py", "nbconvert_exporter": "python", "name": "python", "codemirror_mode": {"version": 2, "name": "ipython"}, "version": "2.7.11", "mimetype": "text/x-python", "pygments_lexer": "ipython2"}}, "nbformat_minor": 0, "nbformat": 4}