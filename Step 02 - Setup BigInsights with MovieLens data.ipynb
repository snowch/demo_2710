{"nbformat_minor": 0, "metadata": {"language_info": {"version": "2.7.11", "codemirror_mode": {"name": "ipython", "version": 2}, "pygments_lexer": "ipython2", "name": "python", "file_extension": ".py", "nbconvert_exporter": "python", "mimetype": "text/x-python"}, "kernelspec": {"language": "python", "name": "python2", "display_name": "Python 2 with Spark 1.6"}}, "nbformat": 4, "cells": [{"source": "## Overview\n\n\nIn this notebook, the cluster is loaded with the movielens ml-1m dataset.", "metadata": {}, "cell_type": "markdown"}, {"source": "### Read the cluster connection information", "metadata": {}, "cell_type": "markdown"}, {"source": "First lets get our previously saved credentials for the cluster", "metadata": {}, "cell_type": "markdown"}, {"execution_count": 13, "outputs": [], "source": "with open('credentials', 'r') as f:\n    (hostname, username, password) = f.readline().split(',')", "metadata": {"collapsed": false}, "cell_type": "code"}, {"source": "### Setup ssh library for running commands on the cluster", "metadata": {}, "cell_type": "markdown"}, {"source": "We can now setup a python ssh library", "metadata": {}, "cell_type": "markdown"}, {"execution_count": 14, "outputs": [], "source": "!pip install --user --upgrade --force --quiet git+https://github.com/snowch/nb_utils", "metadata": {"collapsed": false}, "cell_type": "code"}, {"source": "print version of installed nb_utils for traceability purposes", "metadata": {}, "cell_type": "markdown"}, {"execution_count": 15, "outputs": [{"execution_count": 15, "output_type": "execute_result", "data": {"text/plain": "{u'object': {u'sha': u'04d1ae56e6093a2ac52818661bd8679df2a36c9b',\n  u'type': u'commit',\n  u'url': u'https://api.github.com/repos/snowch/nb_utils/git/commits/04d1ae56e6093a2ac52818661bd8679df2a36c9b'},\n u'ref': u'refs/heads/master',\n u'url': u'https://api.github.com/repos/snowch/nb_utils/git/refs/heads/master'}"}, "metadata": {}}], "source": "import requests, json\nrequests.get('https://api.github.com/repos/snowch/nb_utils/git/refs/heads/master').json()", "metadata": {"collapsed": false}, "cell_type": "code"}, {"source": "load the ssh utilities", "metadata": {}, "cell_type": "markdown"}, {"execution_count": 16, "outputs": [], "source": "from ssh_utils import ssh_utils\nssh = ssh_utils.SshUtil(hostname, username, password)", "metadata": {"collapsed": true}, "cell_type": "code"}, {"source": "### Retrieve the ml-1m dataset", "metadata": {}, "cell_type": "markdown"}, {"execution_count": 17, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Archive:  ml-1m.zip\n   creating: ml-1m/\n  inflating: ml-1m/movies.dat\n  inflating: ml-1m/ratings.dat\n  inflating: ml-1m/README\n  inflating: ml-1m/users.dat\n"}], "source": "# make sure we don't have any data hanging around from previous runs\nssh.cmd('rm -rf ml-1m ml-1m.zip movies.dat users.dat ratings.dat')\n\n# retrieve the data to BigInsights local filesystem\nssh.cmd('wget --quiet http://files.grouplens.org/datasets/movielens/ml-1m.zip')\n\n# unzip the data\nssh.cmd('unzip ml-1m.zip')", "metadata": {"collapsed": false}, "cell_type": "code"}, {"source": "### Upload the data to WebHDFS", "metadata": {}, "cell_type": "markdown"}, {"execution_count": 18, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Deleted ratings.dat\n"}], "source": "# make sure we don't have any data hanging around from previous runs\nssh.cmd('''\n    hdfs dfs -rm -f -skipTrash ./ratings.dat\n    hdfs dfs -rm -r -f -skipTrash ./rating\n    hdfs dfs -rm -r -f -skipTrash ./recommender_model\n''')", "metadata": {"collapsed": false}, "cell_type": "code"}, {"source": "Copy the data from the BigInsights local file system to HDDS and verify that it was copied", "metadata": {}, "cell_type": "markdown"}, {"execution_count": 19, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Found 2 items\ndrwxr-xr-x   - demouser hdfs          0 2016-11-02 10:37 .sparkStaging\n-rw-r--r--   3 demouser hdfs   24594131 2016-11-02 15:08 ratings.dat\n"}], "source": "ssh.cmd('''\n    hdfs dfs -put ./ml-1m/ratings.dat ./ratings.dat\n    hdfs dfs -ls ./\n''')", "metadata": {"collapsed": false}, "cell_type": "code"}, {"source": "Finally, let's remove the data we downloaded to the local filesystem.", "metadata": {}, "cell_type": "markdown"}, {"execution_count": 20, "outputs": [], "source": "ssh.cmd('rm -rf ml-1m ml-1m.zip')", "metadata": {"collapsed": true}, "cell_type": "code"}, {"execution_count": null, "outputs": [], "source": "", "metadata": {"collapsed": true}, "cell_type": "code"}, {"execution_count": null, "outputs": [], "source": "", "metadata": {"collapsed": true}, "cell_type": "code"}]}